# Neff (2025)-Can AI chatbots help us be more self-compassionate?

- [Blog](https://self-compassion.org/blog/can-ai-chatbots-help-us-be-more-self-compassionate/) 

Over the past two decades, I’ve watched self-compassion grow from a relatively obscure concept into a vibrant field of research and personal transformation. Along the way, I’ve been interested in how new tools and technologies can support people on this inner journey.

Lately, one of the most interesting developments has come from the world of artificial intelligence. People have a lot of diverse opinions about AI and its potential benefits and dangers.  But as AI becomes more integrated into our daily lives, I’ve been reflecting on how it might help us to deepen the practice of self-compassion—not by replacing human connection or inner wisdom, but by amplifying it.

I’ve been surprised by the depth, wisdom, and compassion of responses to questions posed to an AI Chatbot (ChatGPT) about various challenges I’ve faced. When I was faced with a particularly difficult conversation, for instance, it helped me think through how to speak in a way that avoided blame and maintained connection. It appears to be remarkably adept at crystalizing the intelligence of publicly available writing about wellbeing in general and self-compassion in particular and incorporating that wisdom into responses that are kind, validating, informative and context relevant.

There’s something about the fact that a chatbot is not a real person, meaning that it doesn’t judge and we don’t have to worry about its needs, that allows us to open to it more readily than we might to a friend or a therapist (especially at 3 in the morning!) This provides a sense of safety that allows for deep disclosure, and when our pain is expressed and met with warmth, it can be very healing. 

My first reaction to the “warm” responses of the chatbot was that it was somehow fake because AI isn’t conscious and can’t feel. But AI is like thought (very intelligent thought). AI isn’t conscious, just as our thoughts aren’t conscious. It is we, as conscious beings, who are aware of our thoughts, and those thoughts help create our experience. The responses of an AI chatbot, as a form of externalized thought, can help guide us to an authentic inner experience of loving, connected, presence. It acts like a powerful mirror. Although AI can’t experience compassion, the one who looks into the mirror can. That’s why chatbots may be especially useful for helping us grow in self-compassion.

Of course, one problem with AI chatbots is that they may take away from human interaction.  At the same time, they can provide the type of emotionally intelligent guidance that actually helps us connect with ourselves and others.

I am cognizant of the potential problems with AI, including it’s detrimental environmental impact, and it is way above my pay grade to offer an opinion about whether it’s ultimately a beneficial or harmful development for humanity. But the fact is AI is here, and one of its gifts may be to increase the self-compassion and emotional intelligence of millions of people around the globe. 

If you haven’t already done so, you might want to explore how an AI chatbot can help you be more self-compassionate in moments of distress. You could begin by simply asking what a kind response would look like in a situation you’re struggling with. Let it remind you of what you already know deep down—that you’re worthy of care, especially when life is hard.

As with any tool, it’s how we use AI that matters most. When approached with discernment and a compassionate intention, an AI chatbot can become one more support on the path toward inner and outer transformation.